{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Quotebank Exploratory Data Analysis\n",
    "\n",
    "TODO add description"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset loading"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import calendar\n",
    "import os\n",
    "\n",
    "import csv\n",
    "import tld\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "import dask.dataframe as dd\n",
    "\n",
    "client = Client(n_workers=2, threads_per_worker=2, memory_limit='6GB')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DATASET_PATH = \"datasets\"\n",
    "\n",
    "filename = \"quotes-2020.parquet\"\n",
    "\n",
    "dataset = dd.read_parquet(os.path.join(DATASET_PATH, filename))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Convert date column to datetime objects\n",
    "dataset[\"date\"] = dd.to_datetime(dataset[\"date\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Print the dataset\n",
    "dataset.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Missing values\n",
    "\n",
    "Most real-world data is incomplete, with values missing due to various reasons. To understand how missing values affect quotebank, we will count how many missing values exist per column and display some rows with `NaN`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n = len(dataset)\n",
    "print(f\"Number of quotes: {n}\")\n",
    "\n",
    "nans_per_column = dataset.isna().sum(axis=0)\n",
    "\n",
    "print(f\"\\n\\nNaN's per column:\")\n",
    "print(nans_per_column)\n",
    "\n",
    "print(f\"\\n\\nNaN's per column (percentage):\")\n",
    "print(nans_per_column / n)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset[dataset.isna().any(axis=1)].head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The only missing values exist for `qids` and `url_countries`. Values in `qids` can be missing if the author couldn't be attributed and `url_countries` are missing if the domain of the newsportal's url could not be linked to a country in the domains dataset we used. Nothing fishy here."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Phases\n",
    "\n",
    "TODO comment a bit on the phases. consult and copy-paste key info from <https://github.com/epfl-dlab/Quotebank/blob/main/phases.md>). show that we are aware of the phases and how we took care of them"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Quote language\n",
    "\n",
    "TODO check that the quote language is english. Make sure there is no chinese etc. consider dropping non-english quotes because we would prefer to train NLP models that understand only english (for convenience and perhaps feasibility)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Newsportal country distribution\n",
    "\n",
    "We want to understand from which countries the quotes we are working with are coming from\n",
    "\n",
    "TODO visualize number of quotes per country on a world heatmap"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Number of distinct quotes per day\n",
    "\n",
    "In the search for further interesting patterns, let us first inspect the number of quotes per day. We will only count the distinct quotes and will not incorporate how many times a given quote occurred."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ds_by_day = dataset.set_index(\"date\").resample(\"1D\")\n",
    "number_of_quotes_per_day = ds_by_day.size().compute()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(12, 8))\n",
    "ax.set_title(\"Number of Quotes per Day\")\n",
    "\n",
    "# Major ticks every week.\n",
    "fmt_week = mdates.WeekdayLocator(interval=1)\n",
    "ax.xaxis.set_major_locator(fmt_week)\n",
    "\n",
    "# Minor ticks every day.\n",
    "fmt_day = mdates.DayLocator(interval=1)\n",
    "ax.xaxis.set_minor_locator(fmt_day)\n",
    "\n",
    "# Text in the x axis will be displayed in 'YYYY-mm-dd' format.\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y-%m-%d\"))\n",
    "\n",
    "# Round to nearest months.\n",
    "datemin = np.datetime64(number_of_quotes_per_day.index[0], 'W')\n",
    "datemax = np.datetime64(number_of_quotes_per_day.index[-1], 'W') + np.timedelta64(1, 'W')\n",
    "ax.set_xlim(datemin, datemax)\n",
    "ax.grid(True)\n",
    "ax.plot(number_of_quotes_per_day, c=\"r\", linewidth=1, alpha=0.75, marker=\"o\", linestyle=\"--\", markersize=5)\n",
    "\n",
    "# Rotates and right aligns the x labels, and moves the bottom of the\n",
    "# axes up to make room for them.\n",
    "fig.autofmt_xdate()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Why is there a sharp decrease in the middle of each week. Is it because of the weekdays/weekends?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset[\"day_of_week\"] = dataset[\"date\"].dt.day_name()\n",
    "ds_by_weekdays = dataset.groupby(dataset[\"day_of_week\"])\n",
    "number_of_quotes_per_weekday = ds_by_weekdays.size().compute()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Sort the index by the day of the week\n",
    "days_of_week = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "day_type = (days_of_week[:5], days_of_week[5:])\n",
    "\n",
    "mapping = {day: i for i, day in enumerate(reversed(days_of_week))}\n",
    "key = number_of_quotes_per_weekday.index.map(mapping)\n",
    "number_of_quotes_per_weekday = number_of_quotes_per_weekday.iloc[key.argsort()]\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 8))\n",
    "ax[0].set_title(\"Number of Quotes per Weekday\", fontsize=12)\n",
    "ax[1].set_title(\"Percent of Quotes per Day Type\", fontsize=12)\n",
    "fig.suptitle(\"Day of the Week Analysis\", fontsize=16)\n",
    "\n",
    "colors = [\"#7DBBC3\", \"#7DBBC3\", \"#F4B9B2\", \"#F4B9B2\", \"#F4B9B2\", \"#F4B9B2\", \"#F4B9B2\"]\n",
    "ax[0].barh(number_of_quotes_per_weekday.index, number_of_quotes_per_weekday, edgecolor=\"black\", color=colors)\n",
    "\n",
    "ax[1].pie([number_of_quotes_per_weekday.loc[x].mean() for x in day_type], labels=[\"Weekdays\", \"Weekends\"], autopct='%.1f%%', shadow=True, startangle=90, colors=[\"#F4B9B2\", \"#7DBBC3\"], wedgeprops={'linewidth': 3.0, 'edgecolor': 'white'}, explode=(0, 0.1))\n",
    "plt.tight_layout()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aha, we were right! Apparently many people decide to stay silent during the weekend."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's explore the trends"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "quote_trends_daily = pd.DataFrame({\"n_quotes\": number_of_quotes_per_day}, index=number_of_quotes_per_day.index)\n",
    "quote_trends_7 = quote_trends_daily[\"n_quotes\"].rolling(window=7, center=True, min_periods=5).mean()\n",
    "quote_trends_30 = quote_trends_daily[\"n_quotes\"].rolling(window=30, center=True, min_periods=20).mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot daily, 7-day rolling mean, and 30-day rolling mean\n",
    "fig, ax = plt.subplots(1, figsize=(12, 8))\n",
    "ax.plot(number_of_quotes_per_day, marker=\".\", markersize=4.5, color=\"0.45\", linestyle=\"dotted\", label=\"Daily\")\n",
    "ax.plot(quote_trends_7, linewidth=2, label='7-d Rolling Mean', color=\"b\")\n",
    "ax.plot(quote_trends_30, color=\"0.2\", linewidth=3, label=\"Trend (30-d Rolling Mean)\")\n",
    "\n",
    "# Major ticks every week.\n",
    "fmt_week = mdates.WeekdayLocator(interval=1)\n",
    "ax.xaxis.set_major_locator(fmt_week)\n",
    "\n",
    "# Minor ticks every day.\n",
    "fmt_day = mdates.DayLocator(interval=1)\n",
    "ax.xaxis.set_minor_locator(fmt_day)\n",
    "\n",
    "# Text in the x axis will be displayed in 'YYYY-mm-dd' format.\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y-%m-%d\"))\n",
    "\n",
    "ax.legend()\n",
    "ax.grid(True, linewidth=0.5, linestyle=\"--\")\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"Number of Quotes\")\n",
    "ax.set_title(\"Trends in Number of Quotes\")\n",
    "\n",
    "# Rotates and right aligns the x labels, and moves the bottom of the\n",
    "# axes up to make room for them.\n",
    "fig.autofmt_xdate()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Number of quote occurrences\n",
    "\n",
    "TODO: Explore the number of occurrences"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(12, 8))\n",
    "sns.boxplot(x=dataset[\"numOccurrences\"].astype(np.int64))\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Woah! So many outliers... Or are they really outliers?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(12, 8))\n",
    "hist, bins = np.histogram(dataset[\"numOccurrences\"].astype(np.int64), bins=16)\n",
    "log_bins = np.logspace(np.log10(bins[0]), np.log10(bins[-1]), len(bins))\n",
    "plt.hist(dataset[\"numOccurrences\"].astype(np.int64), bins=log_bins)\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "TODO Comment if these are outliers. I believe they are but that is okay -- they might just be very popular or in some way important quotes. Understand which quotes are sooo quoted (print the top ~20)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Speaker probabilities\n",
    "\n",
    "TODO: Explore speaker probabilities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(12, 8))\n",
    "sns.boxplot(x=dataset[\"speaker_prob\"].astype(np.float64))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(12, 8))\n",
    "ax.hist(dataset[\"speaker_prob\"].astype(np.float64), bins=25)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Lenght of the quote\n",
    "\n",
    "TODO: Explore the length of the quote"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get the number of words per quote\n",
    "dataset[\"n_word\"] = dataset.apply(lambda x: len(re.compile(r'\\w+').findall(x[\"quotation\"])), axis=1, meta=\"np.int64\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(12, 8))\n",
    "sns.boxplot(x=dataset[\"n_word\"])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(12, 8))\n",
    "ax.hist(dataset[\"n_word\"], bins=25)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Haiti earthquake case-study\n",
    "\n",
    "The method we propose to find whether a quote is about a certain disaster is to do simple text searching to match the expected words. To get a feeling about how we would do it and about its feasibility, we give a short case study of searching for quotes about the disaster with the biggest number of daeths -- the Haiti earthquake in 2010.\n",
    "\n",
    "We will explore what results we get in three scenarios. In the respective scenario we will require the quote to contain all following words:\n",
    "1. `haiti`, `earthquake`\n",
    "2. `haiti`, `earthquake`, `2010`\n",
    "3. `earthquake`, `2010`"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Test the regex is working first\n",
    "def contain_all_words_regex(words):\n",
    "    return \"\".join([f\"(?=.*{word})\" for word in words])\n",
    "\n",
    "regex = contain_all_words_regex([\"haiti\", \"earthquake\"])\n",
    "\n",
    "candidates = pd.Series([\n",
    "    \"haiti\",\n",
    "    \"earthquake\",\n",
    "    \"haitiearthquake\",\n",
    "    \"haiti earthquake\",\n",
    "    \"....haiti___earthquake\",\n",
    "    \"earthquake haiti\",\n",
    "    \"haiti earthquake haiti haiti haiti\",\n",
    "    \"hait earthquak\",\n",
    "    \"aiti arthquake\",\n",
    "    \"HAITI...Earthquake\",\n",
    "    \"this is ma string\",\n",
    "    \"rindfleischetikettierungsüberwachungsaufgabenübertragungsgesetz\",\n",
    "])\n",
    "expected_regex_match = pd.Series([\n",
    "    False, False, True, True, True, True, True, False, False, True, False, False\n",
    "])\n",
    "\n",
    "regex_match = candidates.str.lower().str.contains(regex, regex=True)\n",
    "assert((regex_match == expected_regex_match).all())\n",
    "for i in range(len(candidates)):\n",
    "    print(f\"{regex_match.iloc[i]} <-- {candidates.iloc[i]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Prepare bins\n",
    "infimum_date = datetime.date(2008, 9, 1)\n",
    "supremum_date = datetime.date(2020, 4, 17)\n",
    "print(f\"Infimum date: {infimum_date}\")\n",
    "print(f\"Supremum date: {supremum_date}\")\n",
    "\n",
    "bins = np.linspace(calendar.timegm(infimum_date.timetuple()), calendar.timegm(supremum_date.timetuple()), 140)\n",
    "bins = [datetime.date.fromtimestamp(timestamp) for timestamp in bins]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# The three scenarios\n",
    "def quotes_that_contain_all_words(words):\n",
    "    return dataset[dataset.quotation.str.lower().str.contains(contain_all_words_regex(words), regex=True)]\n",
    "\n",
    "for scenario_words in [[\"haiti\", \"earthquake\"], [\"haiti\", \"earthquake\", \"2010\"], [\"earthquake\", \"2010\"]]:\n",
    "    dates = quotes_that_contain_all_words(scenario_words).date.compute()\n",
    "    dates.hist(bins=bins, figsize=(6.4*2.1,4.8*1.2))\n",
    "\n",
    "    plt.title(f\"Quotes containing: {' + '.join(scenario_words)}\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "\n",
    "    v1 = plt.axvline(x=infimum_date, color='r', linestyle='-')\n",
    "    v2 = plt.axvline(x=supremum_date, color='r', linestyle='-')\n",
    "    plt.text(infimum_date - datetime.timedelta(60), plt.ylim()[1]*0.75, infimum_date, rotation=90)\n",
    "    plt.text(supremum_date + datetime.timedelta(20), plt.ylim()[1]*0.75, supremum_date, rotation=90)\n",
    "\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "TODO comment the graphs. we believe this will allow us to bla bla. Warning about not catching all quotes that talk about... Add short discussion about the precision that we can test and the hope that the recall will be good..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Quote cleaning\n",
    "\n",
    "TODO Lowercase everything, handle special characters\n",
    "\n",
    "TODO Not sure if this should be done before EDA or after... Or even in this notebook?!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}